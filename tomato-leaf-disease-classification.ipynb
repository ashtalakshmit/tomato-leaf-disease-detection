{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport cv2 as cv\nimport pytorch_lightning as pl\n\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\nimport torch.optim as optim  \nimport torch\n\n\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV, learning_curve, validation_curve\n\n#import matplotlib.pyplot as plt\n#import seaborn as sns\n#from matplotlib.colors import ListedColormap\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","editable":false,"execution":{"iopub.status.busy":"2021-05-30T23:27:43.317431Z","iopub.execute_input":"2021-05-30T23:27:43.317837Z","iopub.status.idle":"2021-05-30T23:27:43.325640Z","shell.execute_reply.started":"2021-05-30T23:27:43.317805Z","shell.execute_reply":"2021-05-30T23:27:43.324038Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Convolutional Nueral Network\nimport torchmetrics\nclass basicCNNModel(pl.LightningModule):\n    def __init__(self):\n        super(basicCNNModel, self).__init__()\n        kernel = 3\n        stride = 1\n        padding = 1\n        self.layer1 = nn.Sequential(nn.Conv2d(3, out_channels=32, kernel_size=kernel, stride=stride, padding=padding),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(kernel_size=2,stride=2),\n                                   nn.Dropout(0.2))\n        self.layer2 = nn.Sequential(nn.Conv2d(32, out_channels=64, kernel_size=kernel, stride=stride, padding=padding),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(kernel_size=2,stride=2),\n                                   nn.Dropout(0.2))\n        self.layer3 = nn.Sequential(nn.Conv2d(64, out_channels=128, kernel_size=kernel, stride=stride, padding=padding),\n                                   nn.ReLU(),\n                                   nn.MaxPool2d(kernel_size=2,stride=2),\n                                   nn.Dropout(0.2))                                    \n        \n        self.fc1 = nn.Linear(8192,128)\n        self.fc2 = nn.Linear(128,10)\n        \n        \n        # initializing metrics\n        # Accuracy\n        self.train_accuracy = torchmetrics.Accuracy().to(torch.device(\"cuda\", 0))\n        self.valid_accuracy = torchmetrics.Accuracy(compute_on_step=False).to(torch.device(\"cuda\", 0))\n        self.test_accuracy = torchmetrics.Accuracy().to(torch.device(\"cuda\", 0))\n        \n        # AUROC\n        self.train_auroc = torchmetrics.AUROC(num_classes=10).to(torch.device(\"cuda\", 0))\n        self.valid_auroc = torchmetrics.AUROC(num_classes=10).to(torch.device(\"cuda\", 0))\n        self.valid_auroc = torchmetrics.AUROC(num_classes=10).to(torch.device(\"cuda\", 0))\n    \n    \n    def forward(self,x):\n        out = self.layer1(x)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = torch.flatten(out,1)\n        out = nn.ReLU()(self.fc1(out))\n        out = self.fc2(out)\n        return out\n\n    #This contains the manupulation on data that needs to be done only once such as downloading it\n    def prepare_data(self):\n        self.data_dir = \"../input/tomatoleaf/tomato\"\n        #transforms\n        self.train_transform = transforms.Compose([transforms.RandomRotation(30),\n                                      transforms.RandomResizedCrop(64),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.ToTensor()]) \n        self.test_transform = transforms.Compose([transforms.RandomRotation(30),\n                                     transforms.RandomResizedCrop(64),\n                                     transforms.ToTensor()])\n        # split into train and validation\n        self.train_dataset, self.val_dataset = random_split(datasets.ImageFolder(self.data_dir+\"/train\",\n                                                                                 transform = self.train_transform), [7500,2500])\n        self.test_dataset = datasets.ImageFolder(self.data_dir+\"/val\", transform = self.test_transform)\n        \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset, batch_size=32)\n    \n    def val_dataloader(self):\n        return DataLoader(self.val_dataset, batch_size=32)\n    \n    def test_dataloader(self):\n        return DataLoader(self.test_dataset, batch_size=32)\n    \n    def configure_optimizers(self):\n        return optim.Adam(self.parameters())\n    \n    def training_step(self,batch,batch_idx):\n        #extracting input and output from the batch\n        x,labels = batch\n        #doing a forward pass\n        preds = self.forward(x)\n        #CE Loss is a combination of Log Softmax and NLL loss\n        loss = nn.CrossEntropyLoss()(preds,labels)\n        _,actual_preds = torch.max(preds,1)\n        acc = self.train_accuracy(actual_preds,labels)\n        self.log(\"training_loss\",loss,on_epoch=True, prog_bar=True)#, logger=True)\n        self.log(\"train_accuracy\",acc,on_epoch=True, prog_bar=True)#, logger=True)\n\n       \n        output = { \n              #REQUIRED: It ie required for us to return \"loss\"\n            \"loss\":loss,\n            \"train_accuracy\": acc,\n            \"train_preds\":actual_preds,\n            \"train_targets\":labels,\n        }\n       \n        return output\n    \n    def training_epoch_end(self, outputs):\n        avg_loss = torch.stack(\n            tuple(\n                output[\"loss\"]\n                for output in outputs\n            )\n        ).mean()\n\n        avg_acc =  self.train_accuracy.compute()\n\n        preds = []\n        target = []\n        for output in outputs :\n          for idx in range(len(output[\"train_preds\"])):\n            preds.append(output[\"train_preds\"][idx])\n            target.append(output[\"train_targets\"][idx])\n            \n        \n        #auroc_score = self.train_auroc(torch.tensor(preds),torch.tensor(labels))\n        # print(\"Avg Training Accuracy for this epoch : \", avg_acc)\n        #print(\"Avg Training AUROC for this epoch : \", auroc)\n        \n        return     \n    \n    def validation_step(self, batch, batch_idx):\n        preds = self.eval().forward(batch[0])\n        loss = nn.CrossEntropyLoss()(preds,batch[1])\n\n        _,actual_pred = torch.max(preds,1)\n        x,labels = batch\n        acc = self.valid_accuracy(actual_pred,labels)\n        \n        \n        return {\"batch_val_loss\": loss , \"val_accuracy\":acc , \"preds\":actual_pred,\"labels\":labels}\n\n    def validation_epoch_end(self, outputs):\n        avg_loss = torch.stack(\n            tuple(\n                output[\"batch_val_loss\"]\n                for output in outputs\n            )\n        ).mean()\n\n        avg_acc =  self.valid_accuracy.compute()\n\n        preds = []\n        target = []\n        for output in outputs :\n          for idx in range(len(output[\"preds\"])):\n            preds.append(output[\"preds\"][idx])\n            target.append(output[\"labels\"][idx])\n\n        #auroc = self.valid_auroc(torch.tensor(target),torch.tensor(preds))\n        #print(\"Avg Validation Accuracy for this epoch : \", avg_acc)\n        #print(\"Avg Validation AUROC for this epoch : \", auroc)\n        \n        self.log(\"avg_val_loss\",avg_loss, on_epoch=True, prog_bar=True, logger=True)\n        self.log(\"avg_val_acc\",avg_acc, on_epoch=True, prog_bar=True, logger=True)\n        \n        \n        \n        return {\n            \"val_loss\": avg_loss,\n            #\"val_auroc\": auroc,\n            \n        }\n    \n    def test_step(self,batch,batch_idx):\n        x,labels = batch\n        preds = self.eval().forward(x)\n        loss = nn.CrossEntropyLoss()(preds,labels)\n\n        _,actual_pred = torch.max(preds,1)\n        acc = self.test_accuracy(actual_pred,labels)\n        test_metrics = {\n                        \"test_loss\": loss,\n                        \"test_accuracy\" : acc,\n                       }\n        self.log_dict(test_metrics)\n        \n    \n    \ntrainer = pl.Trainer(gpus=1, max_epochs=20)  \n\nmodel = basicCNNModel()\ntrainer.fit(model)\nprint(model)\n\ntrainer.test(model)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T23:36:26.894614Z","iopub.execute_input":"2021-05-30T23:36:26.895164Z","iopub.status.idle":"2021-05-30T23:48:15.982982Z","shell.execute_reply.started":"2021-05-30T23:36:26.895118Z","shell.execute_reply":"2021-05-30T23:48:15.981585Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Validation sanity check: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"188e40963492486a9bc5c1b4fa6e24c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validating: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"basicCNNModel(\n  (layer1): Sequential(\n    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Dropout(p=0.2, inplace=False)\n  )\n  (layer2): Sequential(\n    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Dropout(p=0.2, inplace=False)\n  )\n  (layer3): Sequential(\n    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Dropout(p=0.2, inplace=False)\n  )\n  (fc1): Linear(in_features=8192, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=10, bias=True)\n  (train_accuracy): Accuracy()\n  (valid_accuracy): Accuracy()\n  (test_accuracy): Accuracy()\n  (train_auroc): AUROC()\n  (valid_auroc): AUROC()\n)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Testing: 0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ea7e4949eb34bb9a5a793ba6da17d32"}},"metadata":{}},{"name":"stdout","text":"--------------------------------------------------------------------------------\nDATALOADER:0 TEST RESULTS\n{'test_accuracy': 0.8600000143051147, 'test_loss': 0.3963444232940674}\n--------------------------------------------------------------------------------\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'test_loss': 0.3963444232940674, 'test_accuracy': 0.8600000143051147}]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}